{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed in both numpy and tensorflow for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "np.random.seed(1)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(2)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models, losses\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Activation, Dropout\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\abc\\\\Documents\\\\deeplearning\")\n",
    "diabetes=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Number of times pregnant        768 non-null int64\n",
      "Plasma glucose concentration    768 non-null int64\n",
      "Blood pressure                  768 non-null int64\n",
      "Skin fold thickness             768 non-null int64\n",
      "Insulin Level                   768 non-null int64\n",
      "BMI                             768 non-null float64\n",
      "Diabetes pedigree function      768 non-null float64\n",
      "Age                             768 non-null int64\n",
      "Class                           768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Blood pressure</th>\n",
       "      <th>Skin fold thickness</th>\n",
       "      <th>Insulin Level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  Plasma glucose concentration  Blood pressure  \\\n",
       "0                         6                           148              72   \n",
       "1                         1                            85              66   \n",
       "2                         8                           183              64   \n",
       "3                         1                            89              66   \n",
       "4                         0                           137              40   \n",
       "\n",
       "   Skin fold thickness  Insulin Level   BMI  Diabetes pedigree function  Age  \\\n",
       "0                   35              0  33.6                       0.627   50   \n",
       "1                   29              0  26.6                       0.351   31   \n",
       "2                    0              0  23.3                       0.672   32   \n",
       "3                   23             94  28.1                       0.167   21   \n",
       "4                   35            168  43.1                       2.288   33   \n",
       "\n",
       "   Class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Blood pressure</th>\n",
       "      <th>Skin fold thickness</th>\n",
       "      <th>Insulin Level</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of times pregnant  Plasma glucose concentration  Blood pressure  \\\n",
       "count                768.000000                    768.000000      768.000000   \n",
       "mean                   3.845052                    120.894531       69.105469   \n",
       "std                    3.369578                     31.972618       19.355807   \n",
       "min                    0.000000                      0.000000        0.000000   \n",
       "25%                    1.000000                     99.000000       62.000000   \n",
       "50%                    3.000000                    117.000000       72.000000   \n",
       "75%                    6.000000                    140.250000       80.000000   \n",
       "max                   17.000000                    199.000000      122.000000   \n",
       "\n",
       "       Skin fold thickness  Insulin Level         BMI  \\\n",
       "count           768.000000     768.000000  768.000000   \n",
       "mean             20.536458      79.799479   31.992578   \n",
       "std              15.952218     115.244002    7.884160   \n",
       "min               0.000000       0.000000    0.000000   \n",
       "25%               0.000000       0.000000   27.300000   \n",
       "50%              23.000000      30.500000   32.000000   \n",
       "75%              32.000000     127.250000   36.600000   \n",
       "max              99.000000     846.000000   67.100000   \n",
       "\n",
       "       Diabetes pedigree function         Age       Class  \n",
       "count                  768.000000  768.000000  768.000000  \n",
       "mean                     0.471876   33.240885    0.348958  \n",
       "std                      0.331329   11.760232    0.476951  \n",
       "min                      0.078000   21.000000    0.000000  \n",
       "25%                      0.243750   24.000000    0.000000  \n",
       "50%                      0.372500   29.000000    0.000000  \n",
       "75%                      0.626250   41.000000    1.000000  \n",
       "max                      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=preprocessing.scale(diabetes.iloc[:,0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=diabetes.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(8,))\n",
    "x = Dense(12, activation='relu')(inp)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "out = Dense(1,activation='sigmoid')(x)\n",
    "model = models.Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 411 samples, validate on 103 samples\n",
      "Epoch 1/150\n",
      "411/411 [==============================] - 3s 7ms/step - loss: 0.6383 - acc: 0.6350 - val_loss: 0.6549 - val_acc: 0.5534\n",
      "Epoch 2/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.6139 - acc: 0.6496 - val_loss: 0.6362 - val_acc: 0.5922\n",
      "Epoch 3/150\n",
      "411/411 [==============================] - 0s 190us/step - loss: 0.5928 - acc: 0.6569 - val_loss: 0.6198 - val_acc: 0.6214\n",
      "Epoch 4/150\n",
      "411/411 [==============================] - 0s 146us/step - loss: 0.5744 - acc: 0.6667 - val_loss: 0.6057 - val_acc: 0.6214\n",
      "Epoch 5/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.5588 - acc: 0.6740 - val_loss: 0.5938 - val_acc: 0.6019\n",
      "Epoch 6/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.5457 - acc: 0.7129 - val_loss: 0.5836 - val_acc: 0.6019\n",
      "Epoch 7/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.5346 - acc: 0.7275 - val_loss: 0.5748 - val_acc: 0.6117\n",
      "Epoch 8/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.5253 - acc: 0.7470 - val_loss: 0.5672 - val_acc: 0.6408\n",
      "Epoch 9/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.5172 - acc: 0.7640 - val_loss: 0.5604 - val_acc: 0.6311\n",
      "Epoch 10/150\n",
      "411/411 [==============================] - 0s 212us/step - loss: 0.5102 - acc: 0.7664 - val_loss: 0.5543 - val_acc: 0.6408\n",
      "Epoch 11/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.5040 - acc: 0.7737 - val_loss: 0.5488 - val_acc: 0.6408\n",
      "Epoch 12/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4986 - acc: 0.7762 - val_loss: 0.5439 - val_acc: 0.6408\n",
      "Epoch 13/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.4938 - acc: 0.7762 - val_loss: 0.5392 - val_acc: 0.6602\n",
      "Epoch 14/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.4894 - acc: 0.7737 - val_loss: 0.5350 - val_acc: 0.6505\n",
      "Epoch 15/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.4854 - acc: 0.7713 - val_loss: 0.5313 - val_acc: 0.6505\n",
      "Epoch 16/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4817 - acc: 0.7737 - val_loss: 0.5283 - val_acc: 0.6505\n",
      "Epoch 17/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.4783 - acc: 0.7810 - val_loss: 0.5256 - val_acc: 0.6408\n",
      "Epoch 18/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4751 - acc: 0.7810 - val_loss: 0.5230 - val_acc: 0.6408\n",
      "Epoch 19/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4720 - acc: 0.7810 - val_loss: 0.5205 - val_acc: 0.6505\n",
      "Epoch 20/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4691 - acc: 0.7810 - val_loss: 0.5184 - val_acc: 0.6505\n",
      "Epoch 21/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.4663 - acc: 0.7810 - val_loss: 0.5165 - val_acc: 0.6505\n",
      "Epoch 22/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.4637 - acc: 0.7859 - val_loss: 0.5146 - val_acc: 0.6505\n",
      "Epoch 23/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4612 - acc: 0.7859 - val_loss: 0.5130 - val_acc: 0.6505\n",
      "Epoch 24/150\n",
      "411/411 [==============================] - 0s 146us/step - loss: 0.4590 - acc: 0.7859 - val_loss: 0.5115 - val_acc: 0.6505\n",
      "Epoch 25/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4568 - acc: 0.7908 - val_loss: 0.5103 - val_acc: 0.6602\n",
      "Epoch 26/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4548 - acc: 0.7932 - val_loss: 0.5093 - val_acc: 0.6699\n",
      "Epoch 27/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4528 - acc: 0.7908 - val_loss: 0.5086 - val_acc: 0.6796\n",
      "Epoch 28/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4508 - acc: 0.7908 - val_loss: 0.5080 - val_acc: 0.6893\n",
      "Epoch 29/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.4489 - acc: 0.7932 - val_loss: 0.5073 - val_acc: 0.6990\n",
      "Epoch 30/150\n",
      "411/411 [==============================] - 0s 146us/step - loss: 0.4470 - acc: 0.7932 - val_loss: 0.5067 - val_acc: 0.6990\n",
      "Epoch 31/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4452 - acc: 0.7981 - val_loss: 0.5061 - val_acc: 0.7087\n",
      "Epoch 32/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4434 - acc: 0.8029 - val_loss: 0.5056 - val_acc: 0.7184\n",
      "Epoch 33/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.4417 - acc: 0.8029 - val_loss: 0.5050 - val_acc: 0.7184\n",
      "Epoch 34/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4399 - acc: 0.8005 - val_loss: 0.5045 - val_acc: 0.7184\n",
      "Epoch 35/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.4383 - acc: 0.8029 - val_loss: 0.5042 - val_acc: 0.7282\n",
      "Epoch 36/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4367 - acc: 0.8054 - val_loss: 0.5040 - val_acc: 0.7282\n",
      "Epoch 37/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.4352 - acc: 0.8054 - val_loss: 0.5040 - val_acc: 0.7282\n",
      "Epoch 38/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4338 - acc: 0.8054 - val_loss: 0.5042 - val_acc: 0.7282\n",
      "Epoch 39/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4324 - acc: 0.8054 - val_loss: 0.5044 - val_acc: 0.7282\n",
      "Epoch 40/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4310 - acc: 0.8102 - val_loss: 0.5045 - val_acc: 0.7282\n",
      "Epoch 41/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4297 - acc: 0.8078 - val_loss: 0.5048 - val_acc: 0.7282\n",
      "Epoch 42/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4283 - acc: 0.8078 - val_loss: 0.5051 - val_acc: 0.7282\n",
      "Epoch 43/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4270 - acc: 0.8078 - val_loss: 0.5054 - val_acc: 0.7282\n",
      "Epoch 44/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4258 - acc: 0.8078 - val_loss: 0.5055 - val_acc: 0.7282\n",
      "Epoch 45/150\n",
      "411/411 [==============================] - 0s 151us/step - loss: 0.4246 - acc: 0.8102 - val_loss: 0.5056 - val_acc: 0.7282\n",
      "Epoch 46/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.4234 - acc: 0.8102 - val_loss: 0.5056 - val_acc: 0.7282\n",
      "Epoch 47/150\n",
      "411/411 [==============================] - 0s 146us/step - loss: 0.4223 - acc: 0.8102 - val_loss: 0.5057 - val_acc: 0.7184\n",
      "Epoch 48/150\n",
      "411/411 [==============================] - 0s 151us/step - loss: 0.4212 - acc: 0.8102 - val_loss: 0.5060 - val_acc: 0.7184\n",
      "Epoch 49/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.4202 - acc: 0.8102 - val_loss: 0.5059 - val_acc: 0.7184\n",
      "Epoch 50/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4192 - acc: 0.8102 - val_loss: 0.5062 - val_acc: 0.7184\n",
      "Epoch 51/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4183 - acc: 0.8102 - val_loss: 0.5061 - val_acc: 0.7184\n",
      "Epoch 52/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4174 - acc: 0.8102 - val_loss: 0.5063 - val_acc: 0.7184\n",
      "Epoch 53/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4166 - acc: 0.8127 - val_loss: 0.5060 - val_acc: 0.7184\n",
      "Epoch 54/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4158 - acc: 0.8127 - val_loss: 0.5061 - val_acc: 0.7184\n",
      "Epoch 55/150\n",
      "411/411 [==============================] - 0s 156us/step - loss: 0.4150 - acc: 0.8127 - val_loss: 0.5062 - val_acc: 0.7184\n",
      "Epoch 56/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.4142 - acc: 0.8078 - val_loss: 0.5059 - val_acc: 0.7184\n",
      "Epoch 57/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.4134 - acc: 0.8102 - val_loss: 0.5060 - val_acc: 0.7184\n",
      "Epoch 58/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4126 - acc: 0.8102 - val_loss: 0.5062 - val_acc: 0.7184\n",
      "Epoch 59/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4119 - acc: 0.8102 - val_loss: 0.5063 - val_acc: 0.7282\n",
      "Epoch 60/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.4112 - acc: 0.8127 - val_loss: 0.5061 - val_acc: 0.7282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "411/411 [==============================] - 0s 148us/step - loss: 0.4105 - acc: 0.8102 - val_loss: 0.5064 - val_acc: 0.7282\n",
      "Epoch 62/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.4098 - acc: 0.8127 - val_loss: 0.5068 - val_acc: 0.7282\n",
      "Epoch 63/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4092 - acc: 0.8102 - val_loss: 0.5073 - val_acc: 0.7282\n",
      "Epoch 64/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.4085 - acc: 0.8102 - val_loss: 0.5076 - val_acc: 0.7282\n",
      "Epoch 65/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4078 - acc: 0.8127 - val_loss: 0.5075 - val_acc: 0.7282\n",
      "Epoch 66/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4073 - acc: 0.8151 - val_loss: 0.5079 - val_acc: 0.7282\n",
      "Epoch 67/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4067 - acc: 0.8151 - val_loss: 0.5082 - val_acc: 0.7282\n",
      "Epoch 68/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.4061 - acc: 0.8127 - val_loss: 0.5083 - val_acc: 0.7282\n",
      "Epoch 69/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4056 - acc: 0.8127 - val_loss: 0.5087 - val_acc: 0.7282\n",
      "Epoch 70/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4050 - acc: 0.8102 - val_loss: 0.5087 - val_acc: 0.7282\n",
      "Epoch 71/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4045 - acc: 0.8127 - val_loss: 0.5089 - val_acc: 0.7282\n",
      "Epoch 72/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.4040 - acc: 0.8127 - val_loss: 0.5091 - val_acc: 0.7282\n",
      "Epoch 73/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4035 - acc: 0.8127 - val_loss: 0.5090 - val_acc: 0.7379\n",
      "Epoch 74/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.4030 - acc: 0.8078 - val_loss: 0.5091 - val_acc: 0.7379\n",
      "Epoch 75/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.4025 - acc: 0.8102 - val_loss: 0.5092 - val_acc: 0.7379\n",
      "Epoch 76/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4020 - acc: 0.8102 - val_loss: 0.5094 - val_acc: 0.7379\n",
      "Epoch 77/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.4016 - acc: 0.8102 - val_loss: 0.5096 - val_acc: 0.7379\n",
      "Epoch 78/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.4011 - acc: 0.8102 - val_loss: 0.5099 - val_acc: 0.7379\n",
      "Epoch 79/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.4006 - acc: 0.8102 - val_loss: 0.5096 - val_acc: 0.7379\n",
      "Epoch 80/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.4002 - acc: 0.8102 - val_loss: 0.5097 - val_acc: 0.7379\n",
      "Epoch 81/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.3997 - acc: 0.8102 - val_loss: 0.5099 - val_acc: 0.7379\n",
      "Epoch 82/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3993 - acc: 0.8102 - val_loss: 0.5100 - val_acc: 0.7379\n",
      "Epoch 83/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.3987 - acc: 0.8102 - val_loss: 0.5097 - val_acc: 0.7379\n",
      "Epoch 84/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.3983 - acc: 0.8102 - val_loss: 0.5098 - val_acc: 0.7379\n",
      "Epoch 85/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3979 - acc: 0.8102 - val_loss: 0.5100 - val_acc: 0.7379\n",
      "Epoch 86/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3974 - acc: 0.8102 - val_loss: 0.5100 - val_acc: 0.7379\n",
      "Epoch 87/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.3969 - acc: 0.8102 - val_loss: 0.5099 - val_acc: 0.7476\n",
      "Epoch 88/150\n",
      "411/411 [==============================] - 0s 122us/step - loss: 0.3964 - acc: 0.8102 - val_loss: 0.5096 - val_acc: 0.7476\n",
      "Epoch 89/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3960 - acc: 0.8102 - val_loss: 0.5097 - val_acc: 0.7476\n",
      "Epoch 90/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3955 - acc: 0.8102 - val_loss: 0.5098 - val_acc: 0.7476\n",
      "Epoch 91/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3950 - acc: 0.8102 - val_loss: 0.5095 - val_acc: 0.7476\n",
      "Epoch 92/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.3946 - acc: 0.8102 - val_loss: 0.5096 - val_acc: 0.7476\n",
      "Epoch 93/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3941 - acc: 0.8127 - val_loss: 0.5099 - val_acc: 0.7476\n",
      "Epoch 94/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.3936 - acc: 0.8127 - val_loss: 0.5099 - val_acc: 0.7476\n",
      "Epoch 95/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.3931 - acc: 0.8127 - val_loss: 0.5102 - val_acc: 0.7476\n",
      "Epoch 96/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3926 - acc: 0.8127 - val_loss: 0.5103 - val_acc: 0.7476\n",
      "Epoch 97/150\n",
      "411/411 [==============================] - 0s 153us/step - loss: 0.3920 - acc: 0.8127 - val_loss: 0.5104 - val_acc: 0.7476\n",
      "Epoch 98/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.3915 - acc: 0.8127 - val_loss: 0.5105 - val_acc: 0.7476\n",
      "Epoch 99/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3910 - acc: 0.8127 - val_loss: 0.5106 - val_acc: 0.7476\n",
      "Epoch 100/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3904 - acc: 0.8127 - val_loss: 0.5107 - val_acc: 0.7476\n",
      "Epoch 101/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3899 - acc: 0.8102 - val_loss: 0.5107 - val_acc: 0.7476\n",
      "Epoch 102/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3894 - acc: 0.8127 - val_loss: 0.5108 - val_acc: 0.7476\n",
      "Epoch 103/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.3888 - acc: 0.8127 - val_loss: 0.5109 - val_acc: 0.7476\n",
      "Epoch 104/150\n",
      "411/411 [==============================] - 0s 144us/step - loss: 0.3884 - acc: 0.8127 - val_loss: 0.5116 - val_acc: 0.7476\n",
      "Epoch 105/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3878 - acc: 0.8127 - val_loss: 0.5119 - val_acc: 0.7476\n",
      "Epoch 106/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3872 - acc: 0.8127 - val_loss: 0.5118 - val_acc: 0.7476\n",
      "Epoch 107/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3866 - acc: 0.8127 - val_loss: 0.5118 - val_acc: 0.7476\n",
      "Epoch 108/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3861 - acc: 0.8151 - val_loss: 0.5119 - val_acc: 0.7476\n",
      "Epoch 109/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3855 - acc: 0.8151 - val_loss: 0.5120 - val_acc: 0.7476\n",
      "Epoch 110/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3850 - acc: 0.8151 - val_loss: 0.5121 - val_acc: 0.7476\n",
      "Epoch 111/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3843 - acc: 0.8127 - val_loss: 0.5120 - val_acc: 0.7476\n",
      "Epoch 112/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3838 - acc: 0.8151 - val_loss: 0.5120 - val_acc: 0.7476\n",
      "Epoch 113/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3833 - acc: 0.8151 - val_loss: 0.5120 - val_acc: 0.7476\n",
      "Epoch 114/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3827 - acc: 0.8175 - val_loss: 0.5120 - val_acc: 0.7476\n",
      "Epoch 115/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3821 - acc: 0.8175 - val_loss: 0.5119 - val_acc: 0.7573\n",
      "Epoch 116/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.3816 - acc: 0.8151 - val_loss: 0.5119 - val_acc: 0.7573\n",
      "Epoch 117/150\n",
      "411/411 [==============================] - 0s 146us/step - loss: 0.3811 - acc: 0.8151 - val_loss: 0.5121 - val_acc: 0.7573\n",
      "Epoch 118/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.3806 - acc: 0.8175 - val_loss: 0.5122 - val_acc: 0.7573\n",
      "Epoch 119/150\n",
      "411/411 [==============================] - 0s 139us/step - loss: 0.3800 - acc: 0.8175 - val_loss: 0.5124 - val_acc: 0.7573\n",
      "Epoch 120/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3795 - acc: 0.8200 - val_loss: 0.5125 - val_acc: 0.7573\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 124us/step - loss: 0.3790 - acc: 0.8200 - val_loss: 0.5127 - val_acc: 0.7573\n",
      "Epoch 122/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3784 - acc: 0.8151 - val_loss: 0.5127 - val_acc: 0.7573\n",
      "Epoch 123/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3779 - acc: 0.8151 - val_loss: 0.5128 - val_acc: 0.7670\n",
      "Epoch 124/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3775 - acc: 0.8151 - val_loss: 0.5138 - val_acc: 0.7670\n",
      "Epoch 125/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.3769 - acc: 0.8151 - val_loss: 0.5142 - val_acc: 0.7670\n",
      "Epoch 126/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3764 - acc: 0.8175 - val_loss: 0.5142 - val_acc: 0.7670\n",
      "Epoch 127/150\n",
      "411/411 [==============================] - 0s 127us/step - loss: 0.3760 - acc: 0.8200 - val_loss: 0.5142 - val_acc: 0.7670\n",
      "Epoch 128/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3755 - acc: 0.8200 - val_loss: 0.5145 - val_acc: 0.7670\n",
      "Epoch 129/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3750 - acc: 0.8224 - val_loss: 0.5146 - val_acc: 0.7670\n",
      "Epoch 130/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3745 - acc: 0.8224 - val_loss: 0.5147 - val_acc: 0.7670\n",
      "Epoch 131/150\n",
      "411/411 [==============================] - 0s 134us/step - loss: 0.3741 - acc: 0.8248 - val_loss: 0.5157 - val_acc: 0.7670\n",
      "Epoch 132/150\n",
      "411/411 [==============================] - 0s 136us/step - loss: 0.3736 - acc: 0.8248 - val_loss: 0.5159 - val_acc: 0.7670\n",
      "Epoch 133/150\n",
      "411/411 [==============================] - 0s 141us/step - loss: 0.3732 - acc: 0.8248 - val_loss: 0.5158 - val_acc: 0.7670\n",
      "Epoch 134/150\n",
      "411/411 [==============================] - 0s 214us/step - loss: 0.3727 - acc: 0.8224 - val_loss: 0.5159 - val_acc: 0.7670\n",
      "Epoch 135/150\n",
      "411/411 [==============================] - 0s 175us/step - loss: 0.3723 - acc: 0.8224 - val_loss: 0.5167 - val_acc: 0.7670\n",
      "Epoch 136/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3718 - acc: 0.8224 - val_loss: 0.5167 - val_acc: 0.7670\n",
      "Epoch 137/150\n",
      "411/411 [==============================] - 0s 109us/step - loss: 0.3714 - acc: 0.8224 - val_loss: 0.5168 - val_acc: 0.7670\n",
      "Epoch 138/150\n",
      "411/411 [==============================] - 0s 112us/step - loss: 0.3710 - acc: 0.8200 - val_loss: 0.5176 - val_acc: 0.7670\n",
      "Epoch 139/150\n",
      "411/411 [==============================] - 0s 114us/step - loss: 0.3706 - acc: 0.8224 - val_loss: 0.5180 - val_acc: 0.7670\n",
      "Epoch 140/150\n",
      "411/411 [==============================] - 0s 114us/step - loss: 0.3702 - acc: 0.8224 - val_loss: 0.5180 - val_acc: 0.7670\n",
      "Epoch 141/150\n",
      "411/411 [==============================] - 0s 122us/step - loss: 0.3697 - acc: 0.8224 - val_loss: 0.5181 - val_acc: 0.7670\n",
      "Epoch 142/150\n",
      "411/411 [==============================] - 0s 117us/step - loss: 0.3694 - acc: 0.8224 - val_loss: 0.5188 - val_acc: 0.7670\n",
      "Epoch 143/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3690 - acc: 0.8224 - val_loss: 0.5190 - val_acc: 0.7670\n",
      "Epoch 144/150\n",
      "411/411 [==============================] - 0s 122us/step - loss: 0.3685 - acc: 0.8224 - val_loss: 0.5191 - val_acc: 0.7670\n",
      "Epoch 145/150\n",
      "411/411 [==============================] - 0s 131us/step - loss: 0.3681 - acc: 0.8248 - val_loss: 0.5194 - val_acc: 0.7670\n",
      "Epoch 146/150\n",
      "411/411 [==============================] - 0s 129us/step - loss: 0.3677 - acc: 0.8248 - val_loss: 0.5199 - val_acc: 0.7670\n",
      "Epoch 147/150\n",
      "411/411 [==============================] - 0s 124us/step - loss: 0.3673 - acc: 0.8273 - val_loss: 0.5202 - val_acc: 0.7670\n",
      "Epoch 148/150\n",
      "411/411 [==============================] - 0s 114us/step - loss: 0.3669 - acc: 0.8248 - val_loss: 0.5203 - val_acc: 0.7670\n",
      "Epoch 149/150\n",
      "411/411 [==============================] - 0s 114us/step - loss: 0.3664 - acc: 0.8248 - val_loss: 0.5203 - val_acc: 0.7670\n",
      "Epoch 150/150\n",
      "411/411 [==============================] - 0s 117us/step - loss: 0.3660 - acc: 0.8248 - val_loss: 0.5205 - val_acc: 0.7670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf409828>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split = 0.2, epochs=150, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 0s 79us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.55584013720197001, 0.74409448959696012]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
